con <- url("google.com")
con <- url("www.google.com")
con <- url("http://www.google.com","r")
?url
x <- readlines(con)
x <- readLines(con)
head(x)
con <- url("http://www.facebook.com","r")
?rep
set.seed(1234)
?par
?c
par(mar( = c(0,0,0,0)))
par(mar = c(0,0,0,0))
PAR
par
x<- rnorm(12, mean = rep(1:3, each = 4), sd = 0,2)
x<- rnorm(12, mean = rep(1:3, each = 4), sd = 0.2)
x
x<- rnorm(12, mean = rep(1:3, each = 4), sd = 0.2)
x
?rep
?each
x<- rnorm(12, mean = rep(1:3, 4), sd = 0.2)
x
y<- rnorm(12, mean = rep(1:3, 4), sd = 0.2)
plot(x,y, col=blue, pch = 19, cex = 2)
plot(x,y, col="blue", pch = 19, cex = 2)
text(x+0.05,y+0,05, labels = as.character(1:12))
B<-1000
n<- length(gmVol)
a <- available.packages()
head(rownames(a),3)
head(rownames(a),1000)
install.packages("slidify")
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
install.packages(c("slidify", "ggplot2", "devtools"))
library(ggplot2)
search()
find.packages("devtools")
find.package("devtools")
install.packages("devtools")
find.package("devtools")
library(devtools)
find_rtools()
find_rtools()
install.packages("KernSmooth")
library(KernSmooth)
library(swirl)
swirl()
ls()
class(plantq)
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants,10)
tail(plants,15)
summary(plants)
table(plants$Active_Growth_Period).
table(plants$Active_Growth_Period)
str(plants)
?sample
sample(1:6, 4, replace = TRUE)
sample(1:6, 4, replace = TRUE)
sample(1:20, 10)
LETTERS
sample(LETTERS)*
;
sample(LETTERS)
flips<- c(0.3, 0.7)
flips<- sample(c(0,1),100, prob=c(0.3, 0.7))
flips<- sample(c(0,1),100, prob=c(0.3, 0.7),replace = TRUE
)
flips
sum(flips)
?rbinom
rbinom(1, size = 100, prob = 0.7)
flips2 ) = rbinom(100, size = 1, prob = 0.7)
flips2 <- rbinom(100, size = 1, prob = 0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10,mean=100,sd=25)
rpois(5,mean=10)
?rpois
rpois(5,lambda=10)
my_pois<-replicate(100, rpois(5, 10))
my_pois
colmeans(my_pois)
colMeans(my_pois)
cm <- colMeans(my_pois)
hist(cm)
d1 <- Sys.Date()
class(d1)
unclass(d1)
d1
as.Date("1969-01-01").
as.Date("1969-01-01")
d2<-as.Date("1969-01-01")
unclass(d2)
t1<-Sys.time()
t1
class(t1)
unclass(t1)
as.POSIXlt(Sys.time(t2))
t2<-as.POSIXlt(Sys.time())
class(t2)
t2
unclass(t2)
str(unclass(t2))
t2$min
weekdays(d1)
weekdayst1)
weekdays(t1)
months(t1)
quarters(t2)
t3<-"October 17, 1986 08:24"
strptime(t3, "%B %d, %Y %H:%M")
t4<-strptime(t3, "%B %d, %Y %H:%M")
t4
class(t4)
Sys.time() > t1
Sys.time() - t1
difftime(Sys.time(), t1, units = 'days')
data(cars)
?cars
head(cars)
plot(cars)
?plot
plot(x=cars$speed,y=cars$dist)
plot(y=cars$speed,x=cars$dist)
plot(x=cars$speed,y=cars$dist,xlab="Speed")
plot(x=cars$speed,y=cars$dist,xlab="Speed",ylab="Stopping Distance")
plot(x=cars$speed,y=cars$dist,ylab="Stopping Distance")
plot(x=cars$speed,y=cars$dist,xlab="Speed",ylab="Stopping Distance")
plot(cars,main="My Plot")
plot(cars,sub="My Plot Subtitle")
plot(cars)
?par
plot(cars, col = 2)
plot(cars, xlim=c(10,15))
plot(cars, pch=2)
data(mtcars)
?boxplot
boxplot(data=mtcars,formula = mpg ~ cyl)
boxplot(formula = mpg ~ cyl,data=mtcars,)
boxplot(formula = mpg ~ cyl,data=mtcars)
hist(mtcars$mpg)
sample(1:5)
X<- data.frame("var1"=sample(1:5))
X
X<-[sample(1:5)]
X<-[sample(1:5),]
X<-X[sample(1:5),]
X
X<-X[sample(1:5),]
X<- data.frame("var1"=sample(1:5),"var2"=sample(6:10))
X
X<-X[sample(1:5),]
X
X<-X[sample(1:5),]
X
X[1:5,]
X<-X[1:5,]
X
?which
X[which(X$var2>8),]
sort(X$var2,decreasing = TRUE, na.last=TRUE)
X$var2[c(1,3)]
X$var2[c(1,3)]=NA
X
sort(X$var2,decreasing = TRUE, na.last=TRUE)
sort(X$var2, na.last=TRUE)
sort(X$var2)
X[order(X$var1,X$var2),]
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
restData <- read.csv("./data/restaurants.csv")
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl,destfile="./data/restaurants.csv",method="curl")
download.file(fileUrl,destfile="./data/restaurants.csv")
restData <- read.csv("./data/restaurants.csv")
head(restData,n=3)
tail(restData,n=3)
summary(restData)
str(restData)
quantile(restData$councilDistrict,na.rm=TRUE)
quantile(restData$councilDistrict,probs=c(0.5,0.75,0.9))
table(restData$zipCode,useNA="ifany")
table(restData$councilDistrict,restData$zipCode)
sum(is.na(restData$councilDistrict))
any(is.na(restData$councilDistrict))
all(restData$zipCode > 0)
data(UCBAdmissions)
DF = as.data.frame(UCBAdmissions)
summary(DF)
xt <- xtabs(Freq ~ Gender + Admit,data=DF)
xt
xt <- xtabs(Freq ~ Gender + Dept,data=DF)
xt
xt <- xtabs(SUM ~ Gender + Dept,data=DF)
xt <- xtabs(Sum ~ Gender + Dept,data=DF)
warpbreaks$replicate <- rep(1:9, len = 54)
xt = xtabs(breaks ~.,data=warpbreaks)
xt
ftable(xt)
s1 <- seq(1,10,by=2) ; s1
s2 <- seq(1,10,length=3); s2
x <- c(1,3,8,25,100); seq(along = x)
restData$zipGroups = cut(restData$zipCode,breaks=quantile(restData$zipCode))
restData$zipGroups
summary(restData)
?cut
table(restData$zipGroups)
table(restData$zipGroups,restData$zipCode)
?cut2
restData$zcf <- factor(restData$zipCode)
restData$zcf[1:10]
class(restData$zcf)
?factor
library(Hmisc); library(plyr)
restData2 = mutate(restData,zipGroups=cut2(zipCode,g=4))
table(restData2$zipGroups)
yesno <- sample(c("yes","no"),size=10,replace=TRUE)
yesnofac = factor(yesno,levels=c("yes","no"))
relevel(yesnofac,ref="no")
as.numeric(yesnofac)
yesno
yesnofac
?relevel
mtcars$carname <- rownames(mtcars)
carMelt <- melt(mtcars,id=c("carname","gear","cyl"),measure.vars=c("mpg","hp"))
head(carMelt,n=3)
tail(carMelt,n=3)
library(reshape2)
install.packages("reshape2")
library(reshape2)
head(mtcars)
mtcars$carname <- rownames(mtcars)
head(mtcars)
carMelt <- melt(mtcars,id=c("carname","gear","cyl"),measure.vars=c("mpg","hp"))
head(carMelt,n=3)
tail(carMelt,n=3)
ylData <- dcast(carMelt, cyl ~ variable)
cylData <- dcast(carMelt, cyl ~ variable)
cylData <- dcast(carMelt, cyl ~ variable,mean)
cyldata
cylData
head(InsectSprays)
tapply(InsectSprays$count,InsectSprays$spray,sum)
spIns =  split(InsectSprays$count,InsectSprays$spray)
spIns
sprCount = lapply(spIns,sum)
sprCount
unlist(sprCount)
sapply(spIns,sum)
carMelt <- melt(mtcars,id=c("carname","gear","cyl"),measure.vars=c("mpg","hp"))
carMelt
carMelt
head(mtcars)
head(carMelt)
library(data.table)
data <- read.table("Quizz1_data.csv", sep = ",", header = TRUE, na.strings ="NA", quote="")
data <- data.table(data)
data[data$VAL==24,.N, by=VAL]
library(data.table)
install.packages("data.table")
library(data.table)
data <- read.table("Quizz1_data.csv", sep = ",", header = TRUE, na.strings ="NA", quote="")
data <- read.table("Quizz1_data.csv", sep = ",", header = TRUE, na.strings ="NA", quote="")
setwd("C:/Users/n.debernardi/Repos/COursera_Cleaning/Quizz 1")
data <- read.table("Quizz1_data.csv", sep = ",", header = TRUE, na.strings ="NA", quote="")
data <- data.table(data)
data[data$VAL==24,.N, by=VAL]
colIndex <- 7:15
rowIndex<-18:23
dat <- read.xlsx("DATA.gov_NGAP.xlsx",sheetIndex=1,header=TRUE,colIndex=colIndex,rowIndex=rowIndex)
library(xlsx)
install.packages("xlsx")
library(xlsx)
colIndex <- 7:15
rowIndex<-18:23
dat <- read.xlsx("DATA.gov_NGAP.xlsx",sheetIndex=1,header=TRUE,colIndex=colIndex,rowIndex=rowIndex)
sum(dat$Zip*dat$Ext,na.rm=T)
library(XML)
install.packages("XML")
library(XML)
doc <- xmlTreeParse(fileUrl,useInternal= TRUE)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl,useInternal= TRUE)
fileName <- "getdata_data_restaurants.xml"
doc <- xmlTreeParse(fileName,useInternal= TRUE)
rootnode <- xmlRoot(doc)
xmlName(rootNode)
rootnode <- xmlRoot(doc)
xmlName(rootNode)
xmlName(rootNode)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]][[1]]
names(rootNode)
xmlsApply(rootNode,xmlValue)
xmlsApply(rootNode,xmlValue)
xmlApply(rootNode,xmlValue)
xpathSApply(rootNode,"//name",xmlValue)
rootNode[[1]][[1]]
xpathSApply(rootNode,"name",xmlValue)
xpathSApply(rootNode,"zipcode",xmlValue)
xpathSApply(rootNode,"//zipcode",xmlValue)
zipCOdes <-xpathSApply(rootNode,"//zipcode",xmlValue)
zipCodes <-xpathSApply(rootNode,"//zipcode",xmlValue)
unlist(zipCodes)
summary(zipCodes)
summary(as.numeric(zipCodes))
summary(zipCodes)
table(zipCodes)
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl,destfile = "MicroSurvey.csv")
DT<-fread("MicroSurvey.csv")
tapply(DT$pwgtp15,DT$SEX,mean)
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
DT[,mean(pwgtp15),by=SEX]
DT[,mean(pwgtp15),by=SEX]
sapply(split(DT$pwgtp15,DT$SEX),mean)
mean(DT$pwgtp15,by=DT$SEX)
mean(DT$pwgtp15,by=DT$SEX)
sapply(split(DT$pwgtp15,DT$SEX),mean)
DT<-fread("MicroSurvey.csv")
tapply(DT$pwgtp15,DT$SEX,mean)
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
DT[,mean(pwgtp15),by=SEX]
sapply(split(DT$pwgtp15,DT$SEX),mean)
mean(DT$pwgtp15,by=DT$SEX)
sapply(split(DT$pwgtp15,DT$SEX),mean)
